{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
    "from sklearn.metrics import auc,roc_auc_score\n",
    "import xgboost as xgb  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b_train = pd.read_csv('B_train_dummy.csv')\n",
    "b_test =  pd.read_csv('B_test_dummy.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# flags = b_train['flag']\n",
    "# b_train['flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col = [x for x in b_train.columns if x in b_test.columns] \n",
    "col = [x for x in col if x not in ['no','flag']]  \n",
    "# col_1 = []\n",
    "# 可加可不加，效果影响不大，删除缺省值的列\n",
    "# for i in col:\n",
    "#     if '999' not in i:\n",
    "#         col_1.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X,test_X,train_Y,test_Y = train_test_split(b_train[col],b_train['flag'],test_size=0.2,random_state  = 0) \n",
    "watchlist=[(xgb.DMatrix(train_X,label=train_Y),'train'),(xgb.DMatrix(test_X,label=test_Y),'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain_B = xgb.DMatrix(b_train[col],b_train['flag'])\n",
    "# 线上效果为0.600018的参数\n",
    "Trate=0.25 \n",
    "params = {'booster':'gbtree',\n",
    "              'eta': 0.05, \n",
    "              'max_depth': 4,                  \n",
    "              'max_delta_step': 0,\n",
    "              'subsample':1,              \n",
    "              'colsample_bytree': 0.9,      \n",
    "              'base_score': Trate, \n",
    "              'objective': 'binary:logistic', \n",
    "              'lambda':3,\n",
    "              'alpha':5\n",
    "              }\n",
    "params['eval_metric'] = 'auc' \n",
    "model_phase_1_cla_2 = xgb.train(params,dtrain_B,num_boost_round=130,maximize=True,verbose_eval=True) \n",
    "\n",
    "#0.599155\n",
    "# Trate=0.15\n",
    "# params = {'booster':'gbtree',\n",
    "#               'eta': 0.05, \n",
    "#               'max_depth': 3,                  \n",
    "#               'max_delta_step': 0,\n",
    "#               'subsample':1,              \n",
    "#               'colsample_bytree': 0.9,      \n",
    "#               'base_score': Trate, \n",
    "# #               'objective': 'binary:logitraw', \n",
    "#               'objective': 'binary:logistic',\n",
    "#               'lambda':3,\n",
    "#               'alpha':5\n",
    "#               }\n",
    "# params['eval_metric'] = 'auc'\n",
    "# model_phase_1_cla_2 = xgb.train(params,dtrain_B,num_boost_round=130,maximize=True,verbose_eval=True) \n",
    "# model_phase_1_cla = xgb.train(params,xgb.DMatrix(train_X,label=train_Y),num_boost_round=1000,evals=watchlist,early_stopping_rounds=50,maximize=True,verbose_eval=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# 0.594276\n",
    "# Trate=0.25 \n",
    "# params = {'booster':'gbtree',\n",
    "#               'eta': 0.05, \n",
    "#               'max_depth': 5,                  \n",
    "#               'max_delta_step': 0,\n",
    "#               'subsample':1,              \n",
    "#               'colsample_bytree': 0.9,      \n",
    "#               'base_score': Trate, \n",
    "#               'objective': 'binary:logistic', \n",
    "#               'lambda':2,\n",
    "#               'alpha':5\n",
    "#               }\n",
    "# params['eval_metric'] = 'auc' \n",
    "# model_phase_1_cla_2 = xgb.train(params,dtrain_B,num_boost_round=150,maximize=True,verbose_eval=True) \n",
    "# model_phase_1_cla = xgb.train(params,xgb.DMatrix(train_X,label=train_Y),num_boost_round=1000,evals=watchlist,early_stopping_rounds=50,maximize=True,verbose_eval=True)\n",
    "\n",
    "# 0.595855\n",
    "# Trate=0.25 \n",
    "# params = {'booster':'gbtree',\n",
    "#               'eta': 0.05, \n",
    "#               'max_depth': 5,                  \n",
    "#               'max_delta_step': 0,\n",
    "#               'subsample':1,              \n",
    "#               'colsample_bytree': 0.9,      \n",
    "#               'base_score': Trate, \n",
    "#               'objective': 'binary:logistic', \n",
    "#               'lambda':3,\n",
    "#               'alpha':5\n",
    "#               }\n",
    "# params['eval_metric'] = 'auc' \n",
    "# model_phase_1_cla_2 = xgb.train(params,dtrain_B,num_boost_round=150,maximize=True,verbose_eval=True) \n",
    "\n",
    "# 0.594632\n",
    "# Trate=0.25 \n",
    "# params = {'booster':'gbtree',\n",
    "#               'eta': 0.05, \n",
    "#               'max_depth': 5,                  \n",
    "#               'max_delta_step': 0,\n",
    "#               'subsample':1,              \n",
    "#               'colsample_bytree': 0.9,      \n",
    "#               'base_score': Trate, \n",
    "#               'objective': 'binary:logistic', \n",
    "#               'lambda':3,\n",
    "#               'alpha':5\n",
    "#               }\n",
    "# params['eval_metric'] = 'auc' \n",
    "# model_phase_1_cla_2 = xgb.train(params,dtrain_B,num_boost_round=200,maximize=True,verbose_eval=True) \n",
    "\n",
    "#0.596701\n",
    "# Trate=0.25 \n",
    "# params = {'booster':'gbtree',\n",
    "#               'eta': 0.05, \n",
    "#               'max_depth': 5,                  \n",
    "#               'max_delta_step': 0,\n",
    "#               'subsample':1,              \n",
    "#               'colsample_bytree': 0.9,      \n",
    "#               'base_score': Trate, \n",
    "#               'objective': 'binary:logistic', \n",
    "#               'lambda':3,\n",
    "#               'alpha':5\n",
    "#               }\n",
    "# params['eval_metric'] = 'auc' \n",
    "# model_phase_1_cla_2 = xgb.train(params,dtrain_B,num_boost_round=138,maximize=True,verbose_eval=True) \n",
    "\n",
    "# 0.596326\n",
    "# Trate=0.25 \n",
    "# params = {'booster':'gbtree',\n",
    "#               'eta': 0.05, \n",
    "#               'max_depth': 5,                  \n",
    "#               'max_delta_step': 0,\n",
    "#               'subsample':1,              \n",
    "#               'colsample_bytree': 0.9,      \n",
    "#               'base_score': Trate, \n",
    "#               'objective': 'binary:logistic', \n",
    "#               'lambda':3,\n",
    "#               'alpha':5\n",
    "#               }\n",
    "# params['eval_metric'] = 'auc' \n",
    "# model_phase_1_cla_2 = xgb.train(params,dtrain_B,num_boost_round=120,maximize=True,verbose_eval=True) \n",
    "\n",
    "# 0.598221\n",
    "# Trate=0.25 \n",
    "# params = {'booster':'gbtree',\n",
    "#               'eta': 0.05, \n",
    "#               'max_depth': 4,                  \n",
    "#               'max_delta_step': 0,\n",
    "#               'subsample':1,              \n",
    "#               'colsample_bytree': 0.9,      \n",
    "#               'base_score': Trate, \n",
    "#               'objective': 'binary:logistic', \n",
    "#               'lambda':3,\n",
    "#               'alpha':5\n",
    "#               }\n",
    "# params['eval_metric'] = 'auc' \n",
    "# model_phase_1_cla_2 = xgb.train(params,dtrain_B,num_boost_round=150,maximize=True,verbose_eval=True) \n",
    "\n",
    "# 0.599235\n",
    "# Trate=0.25 \n",
    "# params = {'booster':'gbtree',\n",
    "#               'eta': 0.05, \n",
    "#               'max_depth': 4,                  \n",
    "#               'max_delta_step': 0,\n",
    "#               'subsample':1,              \n",
    "#               'colsample_bytree': 0.9,      \n",
    "#               'base_score': Trate, \n",
    "#               'objective': 'binary:logistic', \n",
    "#               'lambda':3,\n",
    "#               'alpha':5\n",
    "#               }\n",
    "# params['eval_metric'] = 'auc' \n",
    "# model_phase_1_cla_2 = xgb.train(params,dtrain_B,num_boost_round=138,maximize=True,verbose_eval=True) \n",
    "\n",
    "\n",
    "# 0.598832\n",
    "# Trate=0.25 \n",
    "# params = {'booster':'gbtree',\n",
    "#               'eta': 0.05, \n",
    "#               'max_depth': 4,                  \n",
    "#               'max_delta_step': 0,\n",
    "#               'subsample':1,              \n",
    "#               'colsample_bytree': 0.9,      \n",
    "#               'base_score': Trate, \n",
    "#               'objective': 'binary:logistic', \n",
    "#               'lambda':3,\n",
    "#               'alpha':5\n",
    "#               }\n",
    "# params['eval_metric'] = 'auc' \n",
    "# model_phase_1_cla_2 = xgb.train(params,dtrain_B,num_boost_round=120,maximize=True,verbose_eval=True) \n",
    "\n",
    "# 0.600018\n",
    "# Trate=0.25 \n",
    "# params = {'booster':'gbtree',\n",
    "#               'eta': 0.05, \n",
    "#               'max_depth': 4,                  \n",
    "#               'max_delta_step': 0,\n",
    "#               'subsample':1,              \n",
    "#               'colsample_bytree': 0.9,      \n",
    "#               'base_score': Trate, \n",
    "#               'objective': 'binary:logistic', \n",
    "#               'lambda':3,\n",
    "#               'alpha':5\n",
    "#               }\n",
    "# params['eval_metric'] = 'auc' \n",
    "# model_phase_1_cla_2 = xgb.train(params,dtrain_B,num_boost_round=130,maximize=True,verbose_eval=True) \n",
    "\n",
    "#0.595537\n",
    "# Trate=0.25 \n",
    "# params = {'booster':'gbtree',\n",
    "#               'eta': 0.05, \n",
    "#               'max_depth': 3,                  \n",
    "#               'max_delta_step': 0,\n",
    "#               'subsample':1,              \n",
    "#               'colsample_bytree': 0.9,      \n",
    "#               'base_score': Trate, \n",
    "#               'objective': 'binary:logistic', \n",
    "#               'lambda':3,\n",
    "#               'alpha':5\n",
    "#               }\n",
    "# params['eval_metric'] = 'auc' \n",
    "# model_phase_1_cla_2 = xgb.train(params,dtrain_B,num_boost_round=150,maximize=True,verbose_eval=True) \n",
    "\n",
    "# 0.593465\n",
    "# Trate=0.25 \n",
    "# params = {'booster':'gbtree',\n",
    "#               'eta': 0.05, \n",
    "#               'max_depth': 3,                  \n",
    "#               'max_delta_step': 0,\n",
    "#               'subsample':1,              \n",
    "#               'colsample_bytree': 0.9,      \n",
    "#               'base_score': Trate, \n",
    "#               'objective': 'binary:logistic', \n",
    "#               'lambda':3,\n",
    "#               'alpha':5\n",
    "#               }\n",
    "# params['eval_metric'] = 'auc' \n",
    "# model_phase_1_cla_2 = xgb.train(params,dtrain_B,num_boost_round=130,maximize=True,verbose_eval=True) \n",
    "\n",
    "\n",
    "#0.594750\n",
    "# Trate=0.25 \n",
    "# params = {'booster':'gbtree',\n",
    "#               'eta': 0.05, \n",
    "#               'max_depth': 3,                  \n",
    "#               'max_delta_step': 0,\n",
    "#               'subsample':1,              \n",
    "#               'colsample_bytree': 0.9,      \n",
    "#               'base_score': Trate, \n",
    "#               'objective': 'binary:logistic', \n",
    "#               'lambda':3,\n",
    "#               'alpha':5\n",
    "#               }\n",
    "# params['eval_metric'] = 'auc' \n",
    "# model_phase_1_cla_2 = xgb.train(params,dtrain_B,num_boost_round=200,maximize=True,verbose_eval=True) \n",
    "\n",
    "# #0.599226\n",
    "# Trate=0.25 \n",
    "# params = {'booster':'gbtree',\n",
    "#               'eta': 0.05, \n",
    "#               'max_depth': 4,                  \n",
    "#               'max_delta_step': 0,\n",
    "#               'subsample':1,              \n",
    "#               'colsample_bytree': 0.9,      \n",
    "#               'base_score': Trate, \n",
    "#               'objective': 'binary:logistic', \n",
    "#               'lambda':3,\n",
    "#               'alpha':5\n",
    "#               }\n",
    "# params['eval_metric'] = 'auc' \n",
    "# model_phase_1_cla_2 = xgb.train(params,dtrain_B,num_boost_round=135,maximize=True,verbose_eval=True) \n",
    "\n",
    "\n",
    "#0.598256\n",
    "# Trate=0.25 \n",
    "# params = {'booster':'gbtree',\n",
    "#               'eta': 0.05, \n",
    "#               'max_depth': 4,                  \n",
    "#               'max_delta_step': 0,\n",
    "#               'subsample':1,              \n",
    "#               'colsample_bytree': 0.9,      \n",
    "#               'base_score': Trate, \n",
    "#               'objective': 'binary:logistic', \n",
    "#               'lambda':3,\n",
    "#               'alpha':5\n",
    "#               }\n",
    "# params['eval_metric'] = 'auc' \n",
    "# model_phase_1_cla_2 = xgb.train(params,dtrain_B,num_boost_round=125,maximize=True,verbose_eval=True) \n",
    "\n",
    "# 0.599600\n",
    "# Trate=0.25 \n",
    "# params = {'booster':'gbtree',\n",
    "#               'eta': 0.05, \n",
    "#               'max_depth': 4,                  \n",
    "#               'max_delta_step': 0,\n",
    "#               'subsample':1,              \n",
    "#               'colsample_bytree': 0.9,      \n",
    "#               'base_score': Trate, \n",
    "#               'objective': 'binary:logistic', \n",
    "#               'lambda':3,\n",
    "#               'alpha':5\n",
    "#               }\n",
    "# params['eval_metric'] = 'auc' \n",
    "# model_phase_1_cla_2 = xgb.train(params,dtrain_B,num_boost_round=132,maximize=True,verbose_eval=True) \n",
    "\n",
    "\n",
    "# 0.599844\n",
    "# Trate=0.25 \n",
    "# params = {'booster':'gbtree',\n",
    "#               'eta': 0.05, \n",
    "#               'max_depth': 4,                  \n",
    "#               'max_delta_step': 0,\n",
    "#               'subsample':1,              \n",
    "#               'colsample_bytree': 0.9,      \n",
    "#               'base_score': Trate, \n",
    "#               'objective': 'binary:logistic', \n",
    "#               'lambda':3,\n",
    "#               'alpha':5\n",
    "#               }\n",
    "# params['eval_metric'] = 'auc' \n",
    "# model_phase_1_cla_2 = xgb.train(params,dtrain_B,num_boost_round=132,maximize=True,verbose_eval=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = model_phase_1_cla_2.predict(xgb.DMatrix(b_test[col_1]))\n",
    "result1 = pd.DataFrame()\n",
    "result1['no'] = b_test['no']\n",
    "result1['pred'] = pred[:]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result1.to_csv('subimit_target.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
